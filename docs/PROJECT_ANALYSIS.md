# Projekt-Retrospektive & Analyse

Basierend auf der Code-Analyse wurden folgende St√§rken, Schw√§chen und H√ºrden identifiziert.

## ‚úÖ Was am besten funktioniert hat (Keep)

1.  **Frontend-Performance (Vanilla JS)**: Der Verzicht auf Frameworks (React/Vue) sorgt f√ºr extrem schnelle Ladezeiten und geringe Komplexit√§t. Die App f√ºhlt sich "snappy" an.
2.  **Hybride Architektur**: Das Prinzip "Statische Config (Basisdaten) + Dynamischer Overlay (Live-Daten)" ist exzellent. Es garantiert, dass die App immer *etwas* anzeigt, auch wenn Scraper ausfallen oder das Backend langsam ist.
3.  **Fallback-Strategien**: Das automatische Einspringen von Wetter-API-Daten (Open-Meteo), wenn modellspezifische Resort-Daten fehlen, sorgt f√ºr eine hohe Datenverf√ºgbarkeit und verhindert "leere" Karten.
4.  **Admin Dashboard**: Die Existenz eines operativen Dashboards zur √úberwachung der Scraper ist f√ºr diese Art von Projekt (hohe Fehleranf√§lligkeit externer Quellen) √ºberlebenswichtig.

## üóëÔ∏è Was wir verwerfen/refactoring sollten (Discard/Change)

1.  **Fragmentierte Scraper-Landschaft**: Die Datei `parsers/index.js` importiert √ºber 50 individuelle Parser-Dateien. Das ist ein **Wartungs-Albtraum**.
    *   *Empfehlung*: Konsolidierung auf wenige "Provider-Parser" (z.B. Intermaps, Sitour API), die generisch f√ºr viele Gebiete funktionieren, statt ma√ügeschneidertem HTML-Scraping f√ºr jedes Resort.
2.  **In-Memory Caching (`Map`)**: `backend/services/cache.js` nutzt lokalen Arbeitsspeicher.
    *   *Problem*: Bei Deployment von >1 Instanz (Skalierung) sind die Caches asynchron. Neustarts leeren den Cache sofort, was zu Lastspitzen beim Wiederanlauf f√ºhrt.
    *   *Empfehlung*: Ersatz durch Redis (oder Supabase Cache), um Zustand unabh√§ngig vom App-Server zu halten.
3.  **Hardcodierte `resorts.json`**: Die Stammdaten (Namen, Koordinaten) liegen im Code.
    *   *Problem*: √Ñnderungen (z.B. Tippfehler, neue URL) erfordern einen Git-Commit & Deploy.
    *   *Empfehlung*: Verlagerung der Stammdaten in die Postgres-DB (Supabase), editierbar via Admin-UI.

## üöß Die gr√∂√üten H√ºrden

### 1. Wartung (H√∂chstes Risiko)
Das Projekt steht und f√§llt mit der Datenqualit√§t. Da HTML-Scraping genutzt wird, bricht das System, sobald Skigebiete ihre Webseiten √§ndern.
*   **L√∂sung**: St√§rkere Entkopplung, Monitoring auf "Stale Data" (nicht nur Error), und aggressive Suche nach stabilen JSON-APIs statt HTML-Parsing.

### 2. Skalierbarkeit
Der aktuelle Scheduler (`pLimit(5)`) und der lokale Cache begrenzen die Skalierbarkeit.
*   **Engpass**: Wenn wir auf 200+ Gebiete erweitern, dauert ein kompletter Durchlauf zu lange.
*   **L√∂sung**: "Queue-Worker-Pattern". Der Scheduler pushed Jobs (z.B. "Update Zugspitze") in eine Queue (Redis/Supabase), und Worker arbeiten diese parallel ab.

### 3. Sicherheit
*   **Auth**: `basic-auth` mit *einem* globalen Passwort ist unsicher f√ºr Kollaboration.
*   **L√∂sung**: Umstellung auf JWT oder Supabase Auth f√ºr den Admin-Bereich.

### 4. Performance
*   **API Limits**: Die Abh√§ngigkeit von externen APIs (TomTom) f√ºhrt schnell zu Quota-Problemen (wie bereits erlebt).
*   **L√∂sung**: Intelligenteres Caching der Verkehrsdaten (z.B. nur bei Nutzer-Interaktion oder seltener f√ºr entfernte Gebiete) und serverseitiges Caching der TomTom-Antworten (schon teilweise implementiert, aber ausbaubar).
